{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# The Data\n",
    "The data that the TensorFlow 2.0 beginner tutorial uses is the MNIST dataset which is considered a kind of “Hello, World!” for neural networks and deep learning, and it can be downloaded directly from Keras. It is a dataset full of hand-drawn digits ranging from 0–9 with a corresponding label describing what digit the drawing is supposed to be depicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAMnUlEQVR4nO3dYahc9ZnH8d+vtn1jK8TNqMFKblJ8UVnYtAxhSZbqUraJ+iL2RaUBQwpCGo3QQhFNJVTIC2/KtqUv1obbGpquNbXQinlhbiqhGEogOEpW4warTWKbGpIJvoh91dU+++Iey228c+Zmzjlzpnm+Hxhm5jxz5jwM93fPzPnPmb8jQgCufB9puwEA40HYgSQIO5AEYQeSIOxAEh8d58aWLl0aU1NT49wkkMrp06d14cIFL1SrFHbb6yX9QNJVkn4cEdNlj5+amlKv16uySQAlut3uwNrIb+NtXyXpvyTdLukWSRtt3zLq8wFoVpXP7KslvRkRJyPiL5J+LmlDPW0BqFuVsN8o6Y/z7p8plv0d21ts92z3+v1+hc0BqKJK2Bc6CPCh795GxExEdCOi2+l0KmwOQBVVwn5G0k3z7n9K0tvV2gHQlCphf1HSzbZX2P64pK9I2l9PWwDqNvLQW0S8Z/sBSQc1N/S2JyJeq60zALWqNM4eEc9Jeq6mXgA0iK/LAkkQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5KoNGWz7dOS3pX0vqT3IqJbR1MA6lcp7IV/j4gLNTwPgAbxNh5IomrYQ9Kvbb9ke8tCD7C9xXbPdq/f71fcHIBRVQ372oj4nKTbJW2z/flLHxARMxHRjYhup9OpuDkAo6oU9oh4u7g+L+kZSavraApA/UYOu+2rbX/yg9uSvijpeF2NAahXlaPx10t6xvYHz/NURMzW0hVQg4sXLw6sPf7446XrvvDCC6X12dnyP/X169eX1g8cOFBab8LIYY+Ik5L+pcZeADSIoTcgCcIOJEHYgSQIO5AEYQeSqONEGGAkR44cKa0fPny4tF51eKxJU1NTrW17EPbsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+woVXaaqDT8VNGZmZmBtVOnTo3UUx2GnYK6Y8eO0vqaNWvqbGcs2LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs6PUQw89VFrfvXv3yM+9devW0vqmTZtGfm7pH3MsvEns2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcbZk5ueni6tHzx4sLQ+bKz8wQcfHFhbuXJl6bqo19A9u+09ts/bPj5v2bW2n7f9RnG9pNk2AVS1mLfxP5F06c96PCzpUETcLOlQcR/ABBsa9og4LOmdSxZvkLS3uL1X0l019wWgZqMeoLs+Is5KUnF93aAH2t5iu2e71+/3R9wcgKoaPxofETMR0Y2IbqfTaXpzAAYYNeznbC+TpOL6fH0tAWjCqGHfL2lzcXuzpGfraQdAU4aOs9veJ+k2SUttn5H0bUnTkn5h+15Jf5D05SabxOiGzYG+ffv20vqw31fftWtXaf2aa64prWN8hoY9IjYOKH2h5l4ANIivywJJEHYgCcIOJEHYgSQIO5AEp7he4Xbu3Flp/VtvvbW0fvz48dL6DTfcMLDGKa7jxZ4dSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnP0KcN999w2szc7Olq477BTW5cuXl9bvueee0vq6desG1jg9drzYswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoyzT4CTJ0+W1rdt21ZaLxtLf+qpp0rXvfPOO0vrw8a633rrrdJ62U9VDxtnR73YswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoyzT4CjR4+W1oedk142lr5x46BJeJHN0D277T22z9s+Pm/Zo7b/ZPtYcbmj2TYBVLWYt/E/kbTQz5l8PyJWFZfn6m0LQN2Ghj0iDkt6Zwy9AGhQlQN0D9h+pXibv2TQg2xvsd2z3ev3+xU2B6CKUcP+Q0mflrRK0llJ3x30wIiYiYhuRHQ7nc6ImwNQ1Uhhj4hzEfF+RPxV0o8kra63LQB1GynstpfNu/slSeXz9gJo3dBxdtv7JN0maantM5K+Lek226skhaTTkr7WYI9XvGFj4VXPOW/SzMxMa9vG5Rka9ohY6C/xiQZ6AdAgvi4LJEHYgSQIO5AEYQeSIOxAEpzi+g+gzaG1ffv2ldZPnTpVWn/ssccG1piSebzYswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoyzF44cOVJaX7NmzZg6Ga9h4+iPPPJIaX3FihWl9fvvv/+ye0Iz2LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMsxfWrl1bWl+/fqG5Lefs2LGjdN2mx+inp6cH1rZv317pubdu3Vpa37VrV2mdc9YnB3t2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcfbCsPOyZ2dnB9Zef/310nXXrVtXWj948GBpfdhvs5cp+36AJD399NOldcbJrxxD9+y2b7L9G9snbL9m++vF8mttP2/7jeJ6SfPtAhjVYt7GvyfpmxHxGUn/Kmmb7VskPSzpUETcLOlQcR/AhBoa9og4GxEvF7fflXRC0o2SNkjaWzxsr6S7mmoSQHWXdYDO9pSkz0o6Kun6iDgrzf1DkHTdgHW22O7Z7vX7/WrdAhjZosNu+xOSfinpGxFxcbHrRcRMRHQjotvpdEbpEUANFhV22x/TXNB/FhG/Khafs72sqC+TdL6ZFgHUYejQm21LekLSiYj43rzSfkmbJU0X18820uGYPPnkk6X1nTt3DqyVDctJ0u7du0vrw04jXb58eWn97rvvHlhbuXJl6brIYzHj7GslbZL0qu1jxbJvaS7kv7B9r6Q/SPpyMy0CqMPQsEfEbyV5QPkL9bYDoCl8XRZIgrADSRB2IAnCDiRB2IEkOMW1MOznng8cODCmToBmsGcHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkhobd9k22f2P7hO3XbH+9WP6o7T/ZPlZc7mi+XQCjWswkEe9J+mZEvGz7k5Jesv18Uft+RPxnc+0BqMti5mc/K+lscftd2yck3dh0YwDqdVmf2W1PSfqspKPFogdsv2J7j+0lA9bZYrtnu9fv9ys1C2B0iw677U9I+qWkb0TERUk/lPRpSas0t+f/7kLrRcRMRHQjotvpdGpoGcAoFhV22x/TXNB/FhG/kqSIOBcR70fEXyX9SNLq5toEUNVijsZb0hOSTkTE9+YtXzbvYV+SdLz+9gDUZTFH49dK2iTpVdvHimXfkrTR9ipJIem0pK810iGAWizmaPxvJXmB0nP1twOgKXyDDkiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kIQjYnwbs/uS3pq3aKmkC2Nr4PJMam+T2pdEb6Oqs7flEbHg77+NNewf2rjdi4huaw2UmNTeJrUvid5GNa7eeBsPJEHYgSTaDvtMy9svM6m9TWpfEr2Naiy9tfqZHcD4tL1nBzAmhB1IopWw215v+3Xbb9p+uI0eBrF92varxTTUvZZ72WP7vO3j85Zda/t5228U1wvOsddSbxMxjXfJNOOtvnZtT38+9s/stq+S9DtJ/yHpjKQXJW2MiP8dayMD2D4tqRsRrX8Bw/bnJf1Z0k8j4p+LZd+R9E5ETBf/KJdExEMT0tujkv7c9jTexWxFy+ZPMy7pLklfVYuvXUlfd2sMr1sbe/bVkt6MiJMR8RdJP5e0oYU+Jl5EHJb0ziWLN0jaW9zeq7k/lrEb0NtEiIizEfFycftdSR9MM97qa1fS11i0EfYbJf1x3v0zmqz53kPSr22/ZHtL280s4PqIOCvN/fFIuq7lfi41dBrvcbpkmvGJee1Gmf68qjbCvtBUUpM0/rc2Ij4n6XZJ24q3q1icRU3jPS4LTDM+EUad/ryqNsJ+RtJN8+5/StLbLfSxoIh4u7g+L+kZTd5U1Oc+mEG3uD7fcj9/M0nTeC80zbgm4LVrc/rzNsL+oqSbba+w/XFJX5G0v4U+PsT21cWBE9m+WtIXNXlTUe+XtLm4vVnSsy328ncmZRrvQdOMq+XXrvXpzyNi7BdJd2juiPzvJT3SRg8D+lop6X+Ky2tt9yZpn+be1v2f5t4R3SvpnyQdkvRGcX3tBPX235JelfSK5oK1rKXe/k1zHw1fkXSsuNzR9mtX0tdYXje+LgskwTfogCQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJ/wcCK9MxAxwZjQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "image_index = 35\n",
    "\n",
    "# 데이터중 하나를 출력해본다.\n",
    "print(y_train[image_index])\n",
    "plt.imshow(x_train[image_index], cmap='Greys')\n",
    "plt.show()\n",
    "\n",
    "# 데이터 셋의 크기 확인\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 1 2 4 3 2 7 3 8 6 9 0 5]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "num_classes = 10\n",
    "\n",
    "# To_categorical(): 단순 출력들을 one-hot 형태의 출력으로 변형시킨다.\n",
    "print(y_train[:image_index + 1])\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "print(y_train[:image_index + 1])\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 1. Mnist Training with MLP (Multi Layer Perceptron)\n",
    "We want to create a classifier that classifies MNIST handwritten image into its digit. In other words, classifier will get array which represents MNIST image as input and outputs its label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2972 - accuracy: 0.9136\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1428 - accuracy: 0.9572\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1063 - accuracy: 0.9676\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0902 - accuracy: 0.9722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09023823589086533, 0.9721999764442444]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://towardsdatascience.com/beginners-guide-to-building-neural-networks-in-tensorflow-dab7a09b941d\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "\n",
    "# softmax : 전체합이 1이 되도록 만드는 합수\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=3)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 2. Mnist Training with Convolutional Neural Network (CNN) \n",
    "The basic CNN structure is as follows: Convolution -> Pooling -> Convolution -> Pooling -> Fully Connected Layer -> Output\n",
    "Convolution is the act of taking the original data, and creating feature maps from it.Pooling is down-sampling, most often in the form of \"max-pooling,\" where we select a region, and then take the maximum value in that region, and that becomes the new value for the entire region. Fully Connected Layers are typical neural networks, where all nodes are \"fully connected.\" The convolutional layers are not fully connected like a traditional neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.3610 - accuracy: 0.8967 - val_loss: 0.2061 - val_accuracy: 0.9418\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.1781 - accuracy: 0.9489 - val_loss: 0.1460 - val_accuracy: 0.9582\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 0.1259 - accuracy: 0.9641 - val_loss: 0.1123 - val_accuracy: 0.9672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x223337c18d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.sitepoint.com/keras-digit-recognition-tutorial/\n",
    "# https://victorzhou.com/blog/keras-cnn-tutorial/\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "# Normalize the images.\n",
    "train_images = (train_images / 255) - 0.5\n",
    "test_images = (test_images / 255) - 0.5\n",
    "\n",
    "# Reshape the images.\n",
    "train_images = np.expand_dims(train_images, axis=3)\n",
    "test_images = np.expand_dims(test_images, axis=3)\n",
    "\n",
    "num_filters = 8\n",
    "filter_size = 3\n",
    "\n",
    "# Build the model.\n",
    "model = Sequential([\n",
    "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
    "  MaxPooling2D(pool_size=2), Flatten(), Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "  'adam', loss='categorical_crossentropy', metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "model.fit(\n",
    "  train_images, to_categorical(train_labels), epochs=3,\n",
    "  validation_data=(test_images, to_categorical(test_labels)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Mnist Training with RNN and LSTM\n",
    "We will demonstrate how to use recurrent neural network to predict the handwritten digits MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 806s 13ms/step - loss: 0.4520 - accuracy: 0.8497 - val_loss: 0.1459 - val_accuracy: 0.9548\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 802s 13ms/step - loss: 0.1203 - accuracy: 0.9631 - val_loss: 0.0692 - val_accuracy: 0.9787\n",
      "Test loss: 0.06918824625611306\n",
      "Test accuracy: 0.9786999821662903\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/muhammedfathi/mnist-with-rnn-and-lstm\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, TimeDistributed\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# Training parameters.\n",
    "num_classes = 10\n",
    "\n",
    "# Embedding dimensions.\n",
    "row_hidden = 128\n",
    "col_hidden = 128\n",
    "\n",
    "# The data, split between train and test sets.\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshapes data to 4D for Hierarchical RNN.\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Converts class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "row, col, pixel = x_train.shape[1:]\n",
    "# 4D input.\n",
    "x = Input(shape=(row, col, pixel))\n",
    "\n",
    "# Encodes a row of pixels using TimeDistributed Wrapper.\n",
    "encoded_rows = TimeDistributed(LSTM(row_hidden))(x)\n",
    "\n",
    "# Encodes columns of encoded rows.\n",
    "encoded_columns = LSTM(col_hidden)(encoded_rows)\n",
    "\n",
    "# Final predictions and model.\n",
    "prediction = Dense(num_classes, activation='softmax')(encoded_columns)\n",
    "model = Model(x, prediction)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training.\n",
    "model.fit(\n",
    "    x_train, y_train, batch_size=32, epochs=2, verbose=1, \n",
    "    validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluation.\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
